{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qs7rRG2dkIQd"
   },
   "source": [
    "# Predizione di vittoria nelle battaglie di Pok√©mon\n",
    "\n",
    "*Obiettivo:* Costruire e confrontare diversi modelli per predire il vincitore di un duello Pok√©mon.\n",
    "\n",
    "### Partecipanti:\n",
    "- Daniele Merighi\n",
    "- Luca Palazzini\n",
    "- Lore\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Parametri e Configurazione](#parametri-e-configurazione)\n",
    "2. [Import delle Librerie](#import-delle-librerie)\n",
    "3. [Caricamento e Unione dei Dati](#caricamento-e-unione-dei-dati)\n",
    "4. [Esplorazione dei Dati](#esplorazione-dei-dati)\n",
    "5. [Feature Engineering](#feature-engineering)\n",
    "6. [Analisi delle Correlazioni](#analisi-delle-correlazioni)\n",
    "7. [Addestramento e Tuning dei Modelli](#addestramento-e-tuning-dei-modelli)\n",
    "8. [Valutazione dei Modelli](#valutazione-dei-modelli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametri e Configurazione <a id=\"parametri-e-configurazione\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione dei percorsi e dei parametri globali\n",
    "DATASET_BASE_PATH: str = './datasets'\n",
    "COMBATS_PATH: str = f\"{DATASET_BASE_PATH}/combats.csv\"\n",
    "TYPE_CHART_PATH: str = f\"{DATASET_BASE_PATH}/type_chart.csv\"\n",
    "POKEMON_PATH: str = f\"{DATASET_BASE_PATH}/pokemon.csv\"\n",
    "MODEL_DIR: str = './models'\n",
    "RANDOM_STATE: int = 42\n",
    "# Dimensioni dei set di dati\n",
    "TEST_SIZE: float = 0.2        # 20% per il test\n",
    "VALIDATION_SIZE: float = 0.2  # 20% per la validazione\n",
    "                              # 60% per l'addestramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stRrOKaVPZgS"
   },
   "source": [
    "# Import delle Librerie <a id=\"import-delle-librerie\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a3b95",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Preprocessing dei Dati\n",
    "Applichiamo tecniche di scaling per le variabili numeriche e di encoding per le variabili categoriche. Questa fase √® fondamentale per rendere i dati adatti agli algoritmi di machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1748367577501,
     "user": {
      "displayName": "Luca Palazzini",
      "userId": "16849349752350957766"
     },
     "user_tz": -120
    },
    "id": "VxVx4nu1NQPd"
   },
   "outputs": [],
   "source": [
    "# Librerie base\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "# Compatibilit√° con Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Salvataggio dei modelli\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SK5weryaPXDi"
   },
   "source": [
    "# Caricamento e Unione dei Dati <a id=\"caricamento-e-unione-dei-dati\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803cf1d",
   "metadata": {},
   "source": [
    "### üì• Caricamento dei Dati\n",
    "In questa sezione carichiamo i dataset contenenti le statistiche dei Pok√©mon e le battaglie effettuate. Uniremo successivamente queste informazioni per ottenere un dataset utile alla predizione dell'esito di uno scontro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pokemon_data(combats_path: str, pokemon_path: str) -> pd.DataFrame:\n",
    "   df_combats = pd.read_csv(combats_path)\n",
    "   df_pokemon = pd.read_csv(pokemon_path, index_col=\"#\").fillna(\"None\")\n",
    "   # Prerprocessing del campo winner per avere 0 se vince il primo Pokemon e 1 se vince il_So\n",
    "   df_combats[\"Winner\"] = (df_combats[\"Winner\"] != df_combats[\"First_pokemon\"]).astype(int)\n",
    "   # Merge first and second Pok√©mon stats\n",
    "   return df_combats.merge(\n",
    "      df_pokemon.add_suffix(\"_F\"), how=\"left\",\n",
    "      left_on=\"First_pokemon\", right_index=True\n",
    "   ).merge(\n",
    "      df_pokemon.add_suffix(\"_S\"), how=\"left\",\n",
    "      left_on=\"Second_pokemon\", right_index=True\n",
    "   ).drop(\n",
    "      columns=[\"First_pokemon\", \"Second_pokemon\"]\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22922a38",
   "metadata": {},
   "source": [
    "### üì• Caricamento dei Dati\n",
    "In questa sezione carichiamo i dataset contenenti le statistiche dei Pok√©mon e le battaglie effettuate. Uniremo successivamente queste informazioni per ottenere un dataset utile alla predizione dell'esito di uno scontro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei DataFrame\n",
    "df_type_chart = pd.read_csv(TYPE_CHART_PATH).fillna(\"None\")\n",
    "df_combats: pd.DataFrame = load_pokemon_data(COMBATS_PATH, POKEMON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAyQj8SokwRl"
   },
   "source": [
    "## Esplorazione dei Dati <a id=\"esplorazione-dei-dati\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjv-dvc2nwcO"
   },
   "source": [
    "## Feature Engineering  <a id=\"feature-engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dual_multiplier(df, atk_col, def1_col, def2_col, newcol):\n",
    "   tmp = df_type_chart.rename(columns={\n",
    "      'attack': atk_col,\n",
    "      'defense1': def1_col,\n",
    "      'defense2': def2_col\n",
    "   })\n",
    "   df = df.merge(\n",
    "      tmp[[atk_col, def1_col, def2_col, 'multiplier']],\n",
    "      on=[atk_col, def1_col, def2_col],\n",
    "      how='left'\n",
    "   ).rename(columns={'multiplier': newcol})\n",
    "   df[newcol] = df[newcol].fillna(1.0)\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combats_with_multiplier = df_combats.copy()\n",
    "df_combats_with_multiplier = get_dual_multiplier(df_combats_with_multiplier, 'Type 1_F', 'Type 1_S', 'Type 2_S', 'F1_to_S')\n",
    "df_combats_with_multiplier = get_dual_multiplier(df_combats_with_multiplier, 'Type 2_F', 'Type 1_S', 'Type 2_S', 'F2_to_S')\n",
    "df_combats_with_multiplier = get_dual_multiplier(df_combats_with_multiplier, 'Type 1_S', 'Type 1_F', 'Type 2_F', 'S1_to_F')\n",
    "df_combats_with_multiplier = get_dual_multiplier(df_combats_with_multiplier, 'Type 2_S', 'Type 1_F', 'Type 2_F', 'S2_to_F')\n",
    "df_combats_with_multiplier.drop(columns=['Type 1_F', 'Type 2_F', 'Type 1_S', 'Type 2_S'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimpiazzo delle statistiche con la differenza delle statistiche tra i due pokemon\n",
    "stats: list[str] = ['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']\n",
    "for stat in stats:\n",
    "   df_combats_with_multiplier[f\"delta_{stat}\"] = df_combats_with_multiplier[f'{stat}_F'] - df_combats_with_multiplier[f'{stat}_S']\n",
    "   df_combats_with_multiplier.drop(columns=[f'{stat}_F', f'{stat}_S'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimozione delle colonne non necessarie\n",
    "df_combats_with_multiplier.drop(columns=['Name_F', 'Name_S', 'Generation_F', 'Generation_S'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento e Tuning dei Modelli <a id=\"addestramento-e-tuning-dei-modelli\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per poter addestrare e valutare correttamente i nostri modelli di machine learning, √® fondamentale suddividere il dataset a disposizione in sottoinsiemi distinti. Questo processo ci permette di simulare come il modello si comporterebbe su dati nuovi, fornendo una stima pi√π realistica delle sue performance.\n",
    "\n",
    "### Suddivisione del Dataset\n",
    "\n",
    "Il codice sottostante implementa una strategia di suddivisione in tre parti: **training set**, **validation set** e **test set**.\n",
    "\n",
    "1.  **Separazione Iniziale (Test Set)**  \n",
    "Inizialmente, separiamo la variabile target `Winner` (ci√≤ che vogliamo predire, `y`) dalle features (le variabili usate per la predizione, `X`).  \n",
    "    Successivamente, una porzione del dataset (definita da `TEST_SIZE`) viene messa da parte come **test set** (`X_test`, `y_test`). Questo set verr√† utilizzato **solo alla fine** del processo di sviluppo del modello per ottenere una valutazione finale e imparziale delle sue prestazioni.\n",
    "    * `random_state=RANDOM_STATE`: Garantisce che la suddivisione sia la stessa ogni volta che il codice viene eseguito, rendendo i risultati riproducibili.\n",
    "    * `stratify=y`: Assicura che la proporzione delle classi nella variabile target `y` sia mantenuta sia nel set temporaneo (`X_temp`, `y_temp`) che nel test set. Questo √® cruciale in problemi di classificazione, specialmente con classi sbilanciate, per evitare che uno dei set contenga una rappresentazione distorta delle classi.\n",
    "\n",
    "2.  **Separazione Training e Validation Set**  \n",
    "    Il restante dataset temporaneo (`X_temp`, `y_temp`) viene a sua volta suddiviso in:  \n",
    "    * **Training set** (`X_train`, `y_train`): Utilizzato per addestrare il modello. Il modello \"impara\" dai pattern presenti in questi dati.  \n",
    "    * **Validation set** (`X_val`, `y_val`): Utilizzato durante la fase di sviluppo per la messa a punto degli iperparametri del modello (tuning) e per confrontare le performance di diversi modelli. Questo aiuta a prevenire l'overfitting sul training set. La dimensione √® calcolata in modo da rispettare la proporzione `VALIDATION_SIZE` rispetto al dataset originale. Anche qui, `stratify=y_temp` mantiene la proporzione delle classi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per addestrare i modelli e calcolare il punteggio\n",
    "def train_and_score(pipeline, X_train, y_train, X_test, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "# Creazione del dataset di addestramento e test\n",
    "y: pd.Series = df_combats_with_multiplier['Winner']\n",
    "X: pd.DataFrame = df_combats_with_multiplier.drop(columns=['Winner'])\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=VALIDATION_SIZE / (1.0 - TEST_SIZE),\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56e207",
   "metadata": {},
   "source": [
    "### Preprocessing dei Dati\n",
    "Si procede alla preparazione delle feature prima dell‚Äôaddestramento del modello. In particolare, si distinguono le variabili numeriche da quelle categoriche, e si applicano trasformazioni appropriate a ciascun tipo.\n",
    "\n",
    "`labels_categoriche`: contiene i nomi delle variabili categoriche del dataset. In questo caso, si tratta di variabili booleane che indicano se il primo (F) o il secondo (S) Pok√©mon coinvolto nel combattimento √® leggendario. Tali variabili sono fondamentali poich√© l‚Äôessere leggendario √® spesso associato a migliori statistiche di base.\n",
    "\n",
    "`processed_numerical_columns`: tramite select_dtypes, vengono selezionate automaticamente tutte le colonne numeriche da preprocessare. Questo garantisce una scalabilit√† automatica del codice al variare delle feature numeriche presenti in X.\n",
    "\n",
    "ColumnTransformer:\n",
    "\n",
    "Utilizza due trasformatori principali:\n",
    "\n",
    "* `StandardScaler()` per normalizzare tutte le feature numeriche, centrando le distribuzioni intorno allo 0 con varianza unitaria. Questo √® particolarmente utile per modelli sensibili alle scale (es. SVM, regressione logistica).\n",
    "\n",
    "* `OneHotEncoder(drop='first')` per convertire le feature categoriche in variabili dummy, evitando la trappola della multicollinearit√† rimuovendo la prima categoria.\n",
    "\n",
    "L‚Äôopzione `sparse_output=False` impone un output denso per compatibilit√† con pipeline che non gestiscono bene matrici sparse.\n",
    "\n",
    "`sparse_threshold=0.0` assicura che anche in presenza di feature categoriche, l‚Äôoutput sia denso e uniforme per tutte le trasformazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codifica delle variabili categoriche\n",
    "# Otteniamo le label delle variabili categoriche\n",
    "labels_categoriche: list[str] = ['Legendary_F', 'Legendary_S']\n",
    "# Preprocessing delle variabili categoriche e numeriche\n",
    "processed_numerical_columns: list[str] = X.select_dtypes(include=np.number).columns.tolist();\n",
    "column_encoder: ColumnTransformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "    (\"numeric\", StandardScaler(), processed_numerical_columns),\n",
    "    (\"categorical\", OneHotEncoder(drop='first', sparse_output=False), labels_categoriche),\n",
    "], sparse_threshold=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si implementa un **modello dummy**, che funge da **baseline** per confrontare le prestazioni degli altri modelli pi√π complessi. Non apprende nulla dai dati, ma produce previsioni casuali in base a una strategia predefinita.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modello dummy\n",
    "dummy_model: Pipeline = Pipeline([\n",
    "    ('column_encoder', column_encoder),\n",
    "    ('classifier', DummyClassifier(strategy='uniform', random_state=RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si implementa un **modello lineare** tramite **regressione logistica** con penalizzazione L1 (noto anche come Lasso Logistic Regression). Questo tipo di modello √® particolarmente utile per la **selezione automatica delle feature** e per garantire **sparsit√†** nei coefficienti, migliorando interpretabilit√† e generalizzazione.\n",
    "\n",
    "Viene usato:\n",
    "\n",
    "* `penalty='l1'`: applica una penalizzazione L1 ai coefficienti, inducendo molti di essi a zero. Questo √® utile quando si vuole automatizzare la selezione delle feature, lasciando solo quelle pi√π informative.\n",
    "\n",
    "* `solver='liblinear'`: √® l‚Äôalgoritmo ottimizzatore compatibile con la penalizzazione L1. √à adatto a dataset di dimensioni contenute o moderate e garantisce una buona convergenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1748367587618,
     "user": {
      "displayName": "Luca Palazzini",
      "userId": "16849349752350957766"
     },
     "user_tz": -120
    },
    "id": "Q9YEdrmlxkic",
    "outputId": "8bf124db-0127-4e93-e995-2ead77474a8a"
   },
   "outputs": [],
   "source": [
    "# Modello lineare\n",
    "linear_model: Pipeline = Pipeline([\n",
    "    ('column_encoder', column_encoder),\n",
    "    ('logistic_l1', LogisticRegression(penalty='l1', solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6c28e",
   "metadata": {},
   "source": [
    "Si implementa un **modello di classificazione basato su Random Forest**, una delle tecniche di machine learning supervisionato pi√π robuste e diffuse, in particolare per problemi di classificazione binaria come la previsione del vincitore in una battaglia Pok√©mon.\n",
    "\n",
    "√à un modello ensemble che costruisce molteplici alberi decisionali e li combina per migliorare l'accuratezza e ridurre l'overfitting.\n",
    "\n",
    "L'argomento `n_estimators=100` specifica il numero di alberi nella foresta, garantendo una buona capacit√† di generalizzazione.\n",
    "\n",
    "Il parametro `random_state` assicura ripetibilit√† dell‚Äôesperimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93734,
     "status": "ok",
     "timestamp": 1748367782290,
     "user": {
      "displayName": "Luca Palazzini",
      "userId": "16849349752350957766"
     },
     "user_tz": -120
    },
    "id": "E7a5-GTnwH3y",
    "outputId": "660acc3a-bd8a-49e6-d9c6-10cb94c78202"
   },
   "outputs": [],
   "source": [
    "# Modello decision tree\n",
    "decision_tree_model: Pipeline = Pipeline([\n",
    "    ('column_encoder', column_encoder),\n",
    "    (\"tree\", RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e9773",
   "metadata": {},
   "source": [
    "Si implementa un modello predittivo avanzato tramite **XGBoost (Extreme Gradient Boosting)**, uno degli algoritmi pi√π performanti e utilizzati nel machine learning moderno, specialmente in contesti competitivi e industriali.\n",
    "\n",
    "E' una variante estremamente efficiente del Gradient Boosting Decision Tree (GBDT).\n",
    "\n",
    "Il parametro `eval_metric='logloss'` specifica la funzione di perdita da minimizzare durante il training, adatta a problemi di classificazione binaria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modello xgboost\n",
    "xgboost_model: Pipeline = Pipeline([\n",
    "   ('column_encoder', column_encoder),\n",
    "   (\"xgboost\", XGBClassifier(eval_metric='logloss', random_state=RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando si costruisce un modello di machine learning, come XGBoost, la sua performance dipende molto dai parametri iper (o iperparametri) che regolano il comportamento del modello. Tali parametri non vengono appresi automaticamente dal modello durante il training, ma devono essere impostati a priori dall‚Äôutente.\n",
    "\n",
    "Esempi di iperparametri in XGBoost sono:\n",
    "\n",
    "* n_estimators: numero di alberi da costruire (numero di iterazioni boosting).\n",
    "\n",
    "* max_depth: profondit√† massima di ogni albero.\n",
    "\n",
    "* learning_rate: velocit√† con cui il modello si adatta agli errori.\n",
    "\n",
    "La grid search √® un metodo esaustivo per trovare la miglior combinazione di iperparametri da un insieme predefinito di valori. \n",
    "\n",
    "Per valutare la robustezza della performance di ogni combinazione, si usa la cross-validation:\n",
    "\n",
    "* Il dataset di training viene diviso in k-fold\n",
    "\n",
    "* Il modello viene allenato e valutato 3 volte, ogni volta usando un fold diverso per la validazione e gli altri due per l‚Äôallenamento.\n",
    "\n",
    "* La performance finale √® la media delle 3 valutazioni.\n",
    "\n",
    "`grid_xgb.best_estimator_ ` √® il modello completo, addestrato con i parametri ottimali, pronto per essere usato su dati nuovi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best parameters: {'xgboost__learning_rate': 0.15, 'xgboost__max_depth': 9, 'xgboost__n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Creazione di una griglia di ricerca per ottimizzare i parametri del modello XGBoost\n",
    "param_grid: dict = {\n",
    "   'xgboost__n_estimators': [200, 300, 400],\n",
    "   'xgboost__max_depth': [8, 9, 10],\n",
    "   'xgboost__learning_rate': [0.05, 0.1, 0.15]\n",
    "}\n",
    "grid_xgb: GridSearchCV = GridSearchCV(xgboost_model, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "print(f\"Best parameters: {grid_xgb.best_params_}\")\n",
    "# Modello xgboost\n",
    "xgboost_grid_model: Pipeline = grid_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy score: 0.5035\n",
      "Logistic Regression score: 0.8762\n",
      "Decision Tree score: 0.9601\n",
      "XGBoost score: 0.9616\n",
      "XGBoost with Grid Search score: 0.9627\n"
     ]
    }
   ],
   "source": [
    "# Addestramento e valutazione dei modelli creati\n",
    "models: list = [dummy_model, linear_model, decision_tree_model, xgboost_model, xgboost_grid_model]\n",
    "model_names: list = ['Dummy', 'Logistic Regression', 'Decision Tree', 'XGBoost', 'XGBoost with Grid Search']\n",
    "# Visualizzazione dei risultati dei modelli\n",
    "for model, name in zip(models, model_names):\n",
    "   score: float = train_and_score(model, X_train, y_train, X_test, y_test)\n",
    "   print(f\"{name} score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model: Dummy\n",
      "Saving model: Logistic Regression\n",
      "Saving model: Decision Tree\n",
      "Saving model: XGBoost\n",
      "Saving model: XGBoost with Grid Search\n"
     ]
    }
   ],
   "source": [
    "# Salvataggio dei modelli\n",
    "if not os.path.exists('models'):\n",
    "   os.makedirs('models')\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "   print(f\"Saving model: {name}\")\n",
    "   joblib.dump(model, f'models/{name.replace(\" \", \"_\").lower()}.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione dei Modelli <a id=\"valutazione-dei-modelli\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Dummy', 'Logistic Regression', 'Decision Tree', 'XGBoost', 'XGBoost Optimized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "def extended_validation(model, X_test, y_test, title):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    print(title)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        print(f\"ROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "# Applica a tutti i modelli\n",
    "for i, model in enumerate(models[1:]):\n",
    "    model.fit(X_train, y_train) # Ri-addestra su tutto il training set\n",
    "    extended_validation(model, X_test, y_test, title=f\"Classification Report: {model_names[i+1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(model, X, y, title):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, cv=5, n_jobs=-1, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(train_sizes, np.mean(train_scores, axis=1), label=\"Training score\")\n",
    "    plt.plot(train_sizes, np.mean(test_scores, axis=1), label=\"Cross-validation score\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "for i, model in enumerate(models[1:]):  # Escludi dummy model\n",
    "    plot_learning_curve(\n",
    "        model, \n",
    "        X_temp, \n",
    "        y_temp,\n",
    "        title=f\"Learning Curve: {model_names[i+1]}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
